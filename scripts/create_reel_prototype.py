#!/usr/bin/env python3
"""
ë¦´ìŠ¤ ìë™ ìƒì„± í”„ë¡œí† íƒ€ì…

í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ë¦´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import sys
import asyncio
from pathlib import Path
from dotenv import load_dotenv
import requests
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(project_root / ".env")

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
TEMP_DIR = project_root / "temp"
OUTPUT_DIR = project_root / "output"
TEMP_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)


class ReelMakerPrototype:
    """ë¦´ìŠ¤ ìë™ ìƒì„± í”„ë¡œí† íƒ€ì…"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.openai_key = os.getenv("OPENAI_API_KEY")
        self.elevenlabs_key = os.getenv("ELEVENLABS_API_KEY")
        self.unsplash_key = os.getenv("UNSPLASH_ACCESS_KEY")
        
        print("ğŸ¬ Reel Maker AI - í”„ë¡œí† íƒ€ì…")
        print("=" * 60)
    
    def generate_script(self, keyword: str, duration: int = 30) -> dict:
        """
        OpenAIë¡œ ëŒ€ë³¸ ìƒì„±
        
        Args:
            keyword: í‚¤ì›Œë“œ
            duration: ì˜ìƒ ê¸¸ì´ (ì´ˆ)
        
        Returns:
            ëŒ€ë³¸ ë° ì¥ë©´ ì •ë³´
        """
        print(f"\nğŸ“ 1ë‹¨ê³„: ëŒ€ë³¸ ìƒì„± ì¤‘... (í‚¤ì›Œë“œ: '{keyword}')")
        
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.openai_key)
            
            prompt = f"""
ë‹¤ìŒ í‚¤ì›Œë“œë¡œ {duration}ì´ˆ ë¶„ëŸ‰ì˜ ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í‚¤ì›Œë“œ: {keyword}

ìš”êµ¬ì‚¬í•­:
1. ì²« 3ì´ˆì— ì‹œì„ ì„ ì‚¬ë¡œì¡ëŠ” í›…(Hook) í¬í•¨
2. í•µì‹¬ ë‚´ìš© 3-4ê°œ í¬ì¸íŠ¸ë¡œ êµ¬ì„±
3. ë§ˆì§€ë§‰ì— CTA(Call to Action) í¬í•¨
4. ê° ì¥ë©´ë§ˆë‹¤ í•„ìš”í•œ ì´ë¯¸ì§€ í‚¤ì›Œë“œ ì œì‹œ

í˜•ì‹:
[ì¥ë©´ 1] ë‚´ìš© - ì´ë¯¸ì§€: í‚¤ì›Œë“œ
[ì¥ë©´ 2] ë‚´ìš© - ì´ë¯¸ì§€: í‚¤ì›Œë“œ
...
"""
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë°”ì´ëŸ´ ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            script = response.choices[0].message.content
            
            # ì¥ë©´ íŒŒì‹± (ê°„ë‹¨í•˜ê²Œ)
            scenes = []
            for line in script.split('\n'):
                if line.strip().startswith('[ì¥ë©´') or line.strip().startswith('ì¥ë©´'):
                    scenes.append(line.strip())
            
            if not scenes:
                # ì¥ë©´ êµ¬ë¶„ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ë¡œ
                scenes = [script]
            
            print(f"âœ… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ({len(scenes)}ê°œ ì¥ë©´)")
            print(f"ğŸ’° ì‚¬ìš© í† í°: {response.usage.total_tokens}")
            
            return {
                "script": script,
                "scenes": scenes,
                "keyword": keyword
            }
            
        except Exception as e:
            print(f"âŒ ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def translate_keyword(self, keyword: str) -> str:
        """
        í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (ì´ë¯¸ì§€ ê²€ìƒ‰ìš©)
        
        Args:
            keyword: í•œêµ­ì–´ í‚¤ì›Œë“œ
        
        Returns:
            ì˜ì–´ í‚¤ì›Œë“œ
        """
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.openai_key)
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. ì´ë¯¸ì§€ ê²€ìƒ‰ì— ìµœì í™”ëœ ê°„ë‹¨í•œ ì˜ì–´ ë‹¨ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”: {keyword}\n\nì§§ì€ ì˜ì–´ í‚¤ì›Œë“œë§Œ ë°˜í™˜í•˜ì„¸ìš”."
                    }
                ],
                max_tokens=20,
                temperature=0.3
            )
            
            translated = response.choices[0].message.content.strip()
            print(f"  ğŸŒ ë²ˆì—­: '{keyword}' â†’ '{translated}'")
            return translated
            
        except:
            # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return keyword
    
    def search_images(self, keyword: str, count: int = 5) -> list:
        """
        Unsplashì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            count: ì´ë¯¸ì§€ ê°œìˆ˜
        
        Returns:
            ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nğŸ–¼ï¸  2ë‹¨ê³„: ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘... ('{keyword}')")
        
        # í•œêµ­ì–´ í‚¤ì›Œë“œë©´ ì˜ì–´ë¡œ ë²ˆì—­
        search_keyword = keyword
        if any('\uac00' <= char <= '\ud7a3' for char in keyword):
            search_keyword = self.translate_keyword(keyword)
        
        try:
            params = {
                "query": search_keyword,
                "per_page": count,
                "client_id": self.unsplash_key,
                "orientation": "portrait"  # ì„¸ë¡œ ì´ë¯¸ì§€ ìš°ì„ 
            }
            
            response = requests.get(
                "https://api.unsplash.com/search/photos",
                params=params,
                timeout=10
            )
            
            if response.status_code != 200:
                print(f"âš ï¸  Unsplash ì˜¤ë¥˜: {response.status_code}")
                return []
            
            results = response.json().get("results", [])
            
            images = []
            for photo in results:
                images.append({
                    "url": photo["urls"]["regular"],
                    "download_url": photo["links"]["download_location"],
                    "author": photo["user"]["name"]
                })
            
            print(f"âœ… ì´ë¯¸ì§€ {len(images)}ê°œ ê²€ìƒ‰ ì™„ë£Œ!")
            
            return images
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def download_images(self, images: list, output_dir: Path) -> list:
        """
        ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        
        Args:
            images: ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
        
        Returns:
            ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nâ¬‡ï¸  3ë‹¨ê³„: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        downloaded = []
        
        for i, img in enumerate(images, 1):
            try:
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                response = requests.get(img["url"], timeout=10)
                
                if response.status_code == 200:
                    filepath = output_dir / f"image_{i}.jpg"
                    filepath.write_bytes(response.content)
                    downloaded.append(str(filepath))
                    print(f"  âœ“ ì´ë¯¸ì§€ {i}/{len(images)} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                    
            except Exception as e:
                print(f"  âœ— ì´ë¯¸ì§€ {i} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        print(f"âœ… ì´ {len(downloaded)}ê°œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        
        return downloaded
    
    def select_voice_by_concept(self, keyword: str, script: str) -> dict:
        """
        GPTê°€ ì»¨ì…‰ì— ë§ëŠ” ìŒì„±ì„ ìë™ ì„ íƒ
        
        Args:
            keyword: í‚¤ì›Œë“œ
            script: ëŒ€ë³¸
        
        Returns:
            ìŒì„± ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        print(f"\nğŸ¤ ìŒì„± ì„ íƒ ì¤‘...")
        
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.openai_key)
            
            prompt = f"""
ë‹¤ìŒ ë¦´ìŠ¤ ì»¨ì…‰ì— ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ìŒì„±ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

í‚¤ì›Œë“œ: {keyword}
ëŒ€ë³¸ ì¼ë¶€: {script[:200]}...

ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„±:
1. Sarah (cute) - ë°ê³  ê·€ì—¬ìš´ ì—¬ì„± ëª©ì†Œë¦¬, ë·°í‹°/íŒ¨ì…˜/ì¼ìƒ ì½˜í…ì¸ ì— ì í•©
2. Rachel (calm) - ì°¨ë¶„í•˜ê³  ì§€ì ì¸ ì—¬ì„± ëª©ì†Œë¦¬, êµìœ¡/ë‰´ìŠ¤ ì½˜í…ì¸ ì— ì í•©
3. Adam (energetic) - í™œê¸°ì°¨ê³  ì—­ë™ì ì¸ ë‚¨ì„± ëª©ì†Œë¦¬, ìŠ¤í¬ì¸ /ë™ê¸°ë¶€ì—¬ ì½˜í…ì¸ ì— ì í•©
4. Bella (friendly) - ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ì—¬ì„± ëª©ì†Œë¦¬, ë¸Œì´ë¡œê·¸/ì¼ìƒ ì½˜í…ì¸ ì— ì í•©
5. Antoni (professional) - ì „ë¬¸ì ì¸ ë‚¨ì„± ëª©ì†Œë¦¬, ë¹„ì¦ˆë‹ˆìŠ¤/ê¸°ìˆ  ì½˜í…ì¸ ì— ì í•©

ì¶œë ¥ í˜•ì‹ (JSON):
{{"voice": "Sarah", "reason": "ë·°í‹° ì½˜í…ì¸ ë¼ì„œ ë°ê³  ê·€ì—¬ìš´ í†¤ì´ ì í•©"}}
"""
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ìŒì„± ë””ë ‰í„°ì…ë‹ˆë‹¤. ì»¨ì…‰ì— ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=100,
                temperature=0.3
            )
            
            import json
            result_text = response.choices[0].message.content.strip()
            
            # JSON ì¶”ì¶œ
            if '{' in result_text and '}' in result_text:
                json_start = result_text.index('{')
                json_end = result_text.rindex('}') + 1
                result = json.loads(result_text[json_start:json_end])
                
                selected_voice = result.get("voice", "Sarah")
                reason = result.get("reason", "ìë™ ì„ íƒ")
                
                print(f"  âœ… ì„ íƒëœ ìŒì„±: {selected_voice}")
                print(f"  ğŸ’¡ ì´ìœ : {reason}")
                
                return {"voice": selected_voice, "reason": reason}
            
        except Exception as e:
            print(f"  âš ï¸  ìë™ ì„ íƒ ì‹¤íŒ¨, ê¸°ë³¸ ìŒì„± ì‚¬ìš©: {str(e)}")
        
        # ê¸°ë³¸ê°’
        return {"voice": "Sarah", "reason": "ê¸°ë³¸ ìŒì„±"}
    
    def generate_voice(self, text: str, output_path: Path, voice_name: str = "Sarah") -> str:
        """
        ElevenLabsë¡œ ìŒì„± ìƒì„±
        
        Args:
            text: ëŒ€ë³¸ í…ìŠ¤íŠ¸
            output_path: ì €ì¥ ê²½ë¡œ
            voice_name: ìŒì„± ì´ë¦„
        
        Returns:
            ìŒì„± íŒŒì¼ ê²½ë¡œ
        """
        print(f"\nğŸ™ï¸  4ë‹¨ê³„: ìŒì„± ìƒì„± ì¤‘... (ìŒì„±: {voice_name})")
        
        try:
            # ìŒì„± ID ë§¤í•‘
            voice_map = {
                "Sarah": "EXAVITQu4vr4xnSDxMaL",      # ë°ê³  ê·€ì—¬ìš´ ì—¬ì„±
                "Rachel": "21m00Tcm4TlvDq8ikWAM",     # ì°¨ë¶„í•œ ì—¬ì„±
                "Adam": "pNInz6obpgDQGcFmaJgB",       # í™œê¸°ì°¬ ë‚¨ì„±
                "Bella": "EXAVITQu4vr4xnSDxMaL",      # ì¹œê·¼í•œ ì—¬ì„± (Sarahì™€ ë™ì¼)
                "Antoni": "ErXwobaYiN019PkySvjV"      # ì „ë¬¸ì ì¸ ë‚¨ì„±
            }
            
            voice_id = voice_map.get(voice_name, voice_map["Sarah"])
            
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
            
            headers = {
                "xi-api-key": self.elevenlabs_key,
                "Content-Type": "application/json"
            }
            
            data = {
                "text": text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {
                    "stability": 0.3,          # ë‚®ì„ìˆ˜ë¡ ë” ë°ê³  ê·€ì—¬ìš´ í†¤
                    "similarity_boost": 0.85,  # ë†’ì„ìˆ˜ë¡ ë” í‘œí˜„ë ¥ ìˆìŒ
                    "style": 0.5,              # ìŠ¤íƒ€ì¼ ê°•ë„
                    "use_speaker_boost": True  # ëª©ì†Œë¦¬ ê°•í™”
                }
            }
            
            response = requests.post(
                url,
                json=data,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                output_path.write_bytes(response.content)
                print(f"âœ… ìŒì„± ìƒì„± ì™„ë£Œ! ({len(response.content)} bytes)")
                return str(output_path)
            else:
                print(f"âŒ ìŒì„± ìƒì„± ì‹¤íŒ¨: {response.status_code}")
                print(f"   ì‘ë‹µ: {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ ìŒì„± ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def create_subtitles(self, script: str, duration: float) -> list:
        """
        ëŒ€ë³¸ì—ì„œ í•µì‹¬ ìë§‰ ìƒì„± (íƒ€ì´ë° í¬í•¨)
        
        Args:
            script: ëŒ€ë³¸ í…ìŠ¤íŠ¸
            duration: ì´ ì˜ìƒ ê¸¸ì´
        
        Returns:
            ìë§‰ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{text, start, end}]
        """
        print(f"\nâœï¸  ìë§‰ ìƒì„± ì¤‘...")
        
        # GPTë¡œ í•µì‹¬ ë¬¸ì¥ë§Œ ì¶”ì¶œ
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.openai_key)
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "ëŒ€ë³¸ì—ì„œ ë¦´ìŠ¤ ìë§‰ìœ¼ë¡œ ì í•©í•œ í•µì‹¬ ë¬¸ì¥ 3-5ê°œë§Œ ì¶”ì¶œí•˜ì„¸ìš”. ê° ë¬¸ì¥ì€ ì§§ê³  ì„íŒ©íŠ¸ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ëŒ€ë³¸ì—ì„œ ìë§‰ìœ¼ë¡œ ì“¸ í•µì‹¬ ë¬¸ì¥ 3-5ê°œë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n\n{script}\n\nì¶œë ¥ í˜•ì‹: í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´"
                    }
                ],
                max_tokens=200,
                temperature=0.3
            )
            
            subtitle_text = response.choices[0].message.content.strip()
            sentences = [s.strip() for s in subtitle_text.split('\n') if s.strip()]
            
        except:
            # GPT ì‹¤íŒ¨ ì‹œ ëŒ€ë³¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ
            sentences = []
            for line in script.split('\n'):
                line = line.strip()
                if line and not line.startswith('[') and not line.startswith('ì¥ë©´') and not line.startswith('-') and not line.startswith('ì´ë¯¸ì§€:'):
                    if '?' in line or '!' in line or len(line) > 10:
                        sentences.append(line)
                        if len(sentences) >= 5:
                            break
        
        # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
        sentences = sentences[:5]
        
        if not sentences:
            sentences = ["ìë§‰ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"]
        
        # ê° ìë§‰ì— ê· ë“±í•˜ê²Œ ì‹œê°„ í• ë‹¹
        time_per_subtitle = duration / len(sentences)
        
        subtitles = []
        current_time = 0
        
        for sentence in sentences:
            # ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì—¬ì„œ
            if len(sentence) > 50:
                sentence = sentence[:47] + "..."
            
            subtitles.append({
                'text': sentence,
                'start': current_time,
                'end': current_time + time_per_subtitle
            })
            
            current_time += time_per_subtitle
        
        print(f"âœ… ìë§‰ {len(subtitles)}ê°œ ìƒì„± ì™„ë£Œ!")
        
        return subtitles
    
    def create_video(
        self, 
        images: list, 
        audio_path: str, 
        script: str,
        output_path: Path
    ) -> str:
        """
        FFmpegë¡œ ì˜ìƒ ìƒì„± (ìë§‰ í¬í•¨)
        
        Args:
            images: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            audio_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
            script: ëŒ€ë³¸
            output_path: ì¶œë ¥ ê²½ë¡œ
        
        Returns:
            ìƒì„±ëœ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        """
        print(f"\nğŸ¬ 6ë‹¨ê³„: ì˜ìƒ í•©ì„± ì¤‘...")
        
        try:
            from PIL import Image
            import subprocess
            
            # ìŒì„± ë¡œë“œí•˜ì—¬ ê¸¸ì´ í™•ì¸
            if audio_path and os.path.exists(audio_path):
                # FFprobeë¡œ ìŒì„± ê¸¸ì´ í™•ì¸
                try:
                    result = subprocess.run(
                        ['ffprobe', '-v', 'error', '-show_entries',
                         'format=duration', '-of',
                         'default=noprint_wrappers=1:nokey=1', audio_path],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE
                    )
                    total_duration = float(result.stdout)
                except:
                    total_duration = 30
            else:
                print("âš ï¸  ìŒì„± íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ ê¸¸ì´(30ì´ˆ) ì‚¬ìš©")
                total_duration = 30
            
            # ê° ì´ë¯¸ì§€ë‹¹ ì‹œê°„ ê³„ì‚°
            if images:
                time_per_image = total_duration / len(images)
            else:
                print("âŒ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
                return None
            
            print(f"ğŸ“Š ì˜ìƒ ì •ë³´:")
            print(f"   - ì´ë¯¸ì§€: {len(images)}ê°œ")
            print(f"   - ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")
            print(f"   - ì´ë¯¸ì§€ë‹¹: {time_per_image:.1f}ì´ˆ")
            
            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (1080x1920, 9:16)
            resized_images = []
            for i, img_path in enumerate(images):
                try:
                    img = Image.open(img_path)
                    
                    # ì„¸ë¡œ ê¸¸ì´ë¥¼ 1920ìœ¼ë¡œ ì¡°ì •
                    aspect_ratio = img.width / img.height
                    new_height = 1920
                    new_width = int(new_height * aspect_ratio)
                    
                    img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    
                    # ì¤‘ì•™ í¬ë¡­ (1080x1920)
                    if new_width > 1080:
                        left = (new_width - 1080) // 2
                        img_resized = img_resized.crop((left, 0, left + 1080, 1920))
                    elif new_width < 1080:
                        # íŒ¨ë”© ì¶”ê°€
                        new_img = Image.new('RGB', (1080, 1920), (0, 0, 0))
                        left = (1080 - new_width) // 2
                        new_img.paste(img_resized, (left, 0))
                        img_resized = new_img
                    
                    # ì €ì¥
                    resized_path = TEMP_DIR / f"resized_{i}.jpg"
                    img_resized.save(resized_path, 'JPEG', quality=95)
                    resized_images.append(str(resized_path))
                    
                    print(f"  âœ“ ì´ë¯¸ì§€ {i+1}/{len(images)} ì²˜ë¦¬ ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"  âœ— ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            
            if not resized_images:
                print("âŒ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
                return None
            
            print("\nğŸ¥ FFmpegìœ¼ë¡œ ì˜ìƒ ìƒì„± ì¤‘...")
            
            # ê° ì´ë¯¸ì§€ë¥¼ ì˜ìƒ í´ë¦½ìœ¼ë¡œ ë³€í™˜
            video_clips = []
            for i, img_path in enumerate(resized_images):
                clip_path = TEMP_DIR / f"clip_{i}.mp4"
                
                # ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ ê¸¸ì´ì˜ ì˜ìƒìœ¼ë¡œ ë³€í™˜
                cmd = [
                    'ffmpeg', '-y',
                    '-loop', '1',
                    '-i', img_path,
                    '-t', str(time_per_image),
                    '-vf', 'fps=30,format=yuv420p',
                    '-c:v', 'libx264',
                    '-preset', 'medium',
                    '-crf', '23',
                    str(clip_path)
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode == 0:
                    video_clips.append(str(clip_path))
                else:
                    print(f"  âœ— í´ë¦½ {i+1} ìƒì„± ì‹¤íŒ¨")
            
            if not video_clips:
                print("âŒ ìƒì„±ëœ ì˜ìƒ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤!")
                return None
            
            # 2. ëª¨ë“  í´ë¦½ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
            concat_file = TEMP_DIR / "concat_list.txt"
            with open(concat_file, 'w') as f:
                for clip_path in video_clips:
                    f.write(f"file '{clip_path}'\n")
            
            temp_video = TEMP_DIR / "temp_video.mp4"
            
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', str(concat_file),
                '-c', 'copy',
                str(temp_video)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"âŒ ì˜ìƒ í•©ì¹˜ê¸° ì‹¤íŒ¨: {result.stderr[:200]}")
                return None
            
            print("âœ… ì˜ìƒ í´ë¦½ ìƒì„± ë° í•©ì¹˜ê¸° ì™„ë£Œ!")
            
            # 3. ìë§‰ ìƒì„±
            subtitles = self.create_subtitles(script, total_duration)
            
            # 4. SRT ìë§‰ íŒŒì¼ ìƒì„±
            srt_file = TEMP_DIR / "subtitles.srt"
            with open(srt_file, 'w', encoding='utf-8') as f:
                for i, sub in enumerate(subtitles, 1):
                    # SRT í˜•ì‹
                    start_time = self._format_time(sub['start'])
                    end_time = self._format_time(sub['end'])
                    
                    f.write(f"{i}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{sub['text']}\n")
                    f.write("\n")
            
            print("âœ… SRT ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
            
            # 5. ìŒì„± ë° ìë§‰ ì¶”ê°€
            if audio_path and os.path.exists(audio_path):
                print("ğŸ™ï¸  ìŒì„± ë° ìë§‰ ì¶”ê°€ ì¤‘...")
                
                # í•œêµ­ì–´ í°íŠ¸ ê²½ë¡œ (macOS ê¸°ë³¸ í°íŠ¸)
                font_path = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
                
                # ìë§‰ ìŠ¤íƒ€ì¼ ì„¤ì • (ì‘ê³  í•˜ë‹¨ì— í‘œì‹œ)
                subtitle_filter = (
                    f"subtitles={srt_file}:force_style='"
                    f"FontName=AppleSDGothicNeo-Bold,"
                    f"FontSize=24,"              # ì‘ì€ í¬ê¸°
                    f"PrimaryColour=&HFFFFFF&,"  # í°ìƒ‰
                    f"OutlineColour=&H000000&,"  # ê²€ì€ìƒ‰ í…Œë‘ë¦¬
                    f"Outline=2,"                # í…Œë‘ë¦¬ ë‘ê»˜ ì¤„ì„
                    f"Shadow=1,"                 # ê·¸ë¦¼ì ì¤„ì„
                    f"Alignment=2,"              # í•˜ë‹¨ ì¤‘ì•™
                    f"MarginV=50"                # í•˜ë‹¨ ì—¬ë°± ì¤„ì„ (ë” ì•„ë˜ë¡œ)
                    f"'"
                )
                
                cmd = [
                    'ffmpeg', '-y',
                    '-i', str(temp_video),
                    '-i', audio_path,
                    '-vf', subtitle_filter,
                    '-c:v', 'libx264',
                    '-c:a', 'aac',
                    '-shortest',
                    str(output_path)
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode != 0:
                    print(f"âŒ ìë§‰ ì¶”ê°€ ì‹¤íŒ¨: {result.stderr[:200]}")
                    # ìë§‰ ì—†ì´ ìŒì„±ë§Œ ì¶”ê°€
                    cmd = [
                        'ffmpeg', '-y',
                        '-i', str(temp_video),
                        '-i', audio_path,
                        '-c:v', 'copy',
                        '-c:a', 'aac',
                        '-shortest',
                        str(output_path)
                    ]
                    subprocess.run(cmd, capture_output=True, text=True)
            else:
                # ìŒì„± ì—†ì´ ì €ì¥
                import shutil
                shutil.copy(temp_video, output_path)
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for img in resized_images:
                try:
                    os.remove(img)
                except:
                    pass
            
            # í´ë¦½ íŒŒì¼ë“¤ë„ ì •ë¦¬
            if 'video_clips' in locals():
                for clip in video_clips:
                    try:
                        os.remove(clip)
                    except:
                        pass
            
            try:
                os.remove(temp_video)
                os.remove(concat_file)
                if 'srt_file' in locals():
                    os.remove(srt_file)
            except:
                pass
            
            print(f"âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
            
            return str(output_path)
    
            
        except Exception as e:
            print(f"âŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def _format_time(self, seconds: float) -> str:
        """
        ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            seconds: ì´ˆ ë‹¨ìœ„ ì‹œê°„
        
        Returns:
            HH:MM:SS,mmm í˜•ì‹ ë¬¸ìì—´
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
    
    def create_reel(self, keyword: str, duration: int = 30, voice_style: str = "cute") -> str:
        """
        ì „ì²´ ë¦´ìŠ¤ ìƒì„± í”„ë¡œì„¸ìŠ¤
        
        Args:
            keyword: í‚¤ì›Œë“œ
            duration: ì˜ìƒ ê¸¸ì´
        
        Returns:
            ìƒì„±ëœ ì˜ìƒ ê²½ë¡œ
        """
        print(f"\nğŸš€ '{keyword}' í‚¤ì›Œë“œë¡œ ë¦´ìŠ¤ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤!\n")
        
        try:
            # 1. ëŒ€ë³¸ ìƒì„±
            script_data = self.generate_script(keyword, duration)
            
            # 2. ì´ë¯¸ì§€ ê²€ìƒ‰
            images = self.search_images(keyword, count=5)
            
            if not images:
                print("âš ï¸  ëŒ€ì²´ í‚¤ì›Œë“œë¡œ ì¬ê²€ìƒ‰...")
                images = self.search_images("abstract art", count=5)
            
            # 3. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            downloaded_images = self.download_images(images, TEMP_DIR)
            
            if not downloaded_images:
                print("âŒ ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
                return None
            
            # 4. GPTê°€ ì»¨ì…‰ì— ë§ëŠ” ìŒì„± ì„ íƒ
            voice_info = self.select_voice_by_concept(keyword, script_data["script"])
            
            # 5. ìŒì„± ìƒì„±
            audio_path = TEMP_DIR / "voice.mp3"
            
            # ëŒ€ë³¸ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ê°„ë‹¨í•˜ê²Œ)
            script_text = script_data["script"]
            # '[ì¥ë©´ X]' ê°™ì€ ë§ˆì»¤ ì œê±°
            clean_text = []
            for line in script_text.split('\n'):
                if not line.strip().startswith('[') and not line.strip().startswith('ì¥ë©´'):
                    if line.strip() and not line.strip().startswith('-') and not line.strip().startswith('ì´ë¯¸ì§€:'):
                        clean_text.append(line.strip())
            
            voice_text = ' '.join(clean_text[:8])  # ì²˜ìŒ 8ì¤„
            
            if len(voice_text) < 10:
                voice_text = f"{keyword}ì— ëŒ€í•œ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
            
            voice_path = self.generate_voice(voice_text, audio_path, voice_info["voice"])
            
            # 6. ì˜ìƒ í•©ì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"reel_{keyword}_{timestamp}.mp4"
            output_path = OUTPUT_DIR / output_filename
            
            video_path = self.create_video(
                downloaded_images,
                voice_path,
                script_data["script"],
                output_path
            )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            print("\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...")
            for img in downloaded_images:
                try:
                    os.remove(img)
                except:
                    pass
            
            if voice_path and os.path.exists(voice_path):
                try:
                    os.remove(voice_path)
                except:
                    pass
            
            return video_path
            
        except Exception as e:
            print(f"\nâŒ ë¦´ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       ğŸ¬ Reel Maker AI - í”„ë¡œí† íƒ€ì… v0.1               â•‘
â•‘          í‚¤ì›Œë“œë§Œ ì…ë ¥í•˜ë©´ ë¦´ìŠ¤ ìë™ ìƒì„±!                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # í‚¤ì›Œë“œ ì…ë ¥
    if len(sys.argv) > 1:
        keyword = ' '.join(sys.argv[1:])
    else:
        keyword = input("ğŸ”‘ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    if not keyword:
        print("âŒ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return
    
    # ë¦´ìŠ¤ ìƒì„±
    maker = ReelMakerPrototype()
    video_path = maker.create_reel(keyword)
    
    if video_path:
        print("\n" + "="*60)
        print("ğŸ‰ ë¦´ìŠ¤ ìƒì„± ì™„ë£Œ!")
        print("="*60)
        print(f"ğŸ“ íŒŒì¼: {video_path}")
        print(f"ğŸ“± ì´ì œ ì¸ìŠ¤íƒ€ê·¸ë¨ì— ì—…ë¡œë“œí•˜ì„¸ìš”!")
        print("="*60)
    else:
        print("\nâŒ ë¦´ìŠ¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

